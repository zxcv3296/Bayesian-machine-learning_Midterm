Gaussian Mixture Model (GMM) - EM / Gibbs / Variational Inference
==================================================================

ğŸ“˜ ê°œìš”
------------------------------------------------------------------
ì´ ì €ì¥ì†ŒëŠ” **NumPyë§Œì„ ì‚¬ìš©í•˜ì—¬** Gaussian Mixture Model(GMM)ì„ ì„¸ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì‹¤í—˜ì„ ë‹¤ë£¹ë‹ˆë‹¤.
1. **EM (Expectationâ€“Maximization)** â€” ìµœëŒ€ìš°ë„ ì¶”ì • ê¸°ë°˜
2. **Gibbs Sampling** â€” ì™„ì „ ë² ì´ì§€ì•ˆ ì‚¬í›„ ìƒ˜í”Œë§
3. **Variational Inference (VI)** â€” ê·¼ì‚¬ ì¶”ë¡  (ELBO ìµœì í™”)

ê° ë°©ë²•ì€ `data/G2.txt` 2ì°¨ì› ê°€ìš°ì‹œì•ˆ ë°ì´í„°ì…‹ì„ ëŒ€ìƒìœ¼ë¡œ ì‹¤í—˜ë˜ì—ˆìŠµë‹ˆë‹¤.

------------------------------------------------------------------
ğŸ“‚ í´ë” êµ¬ì¡° ë° íŒŒì¼ ì„¤ëª…
------------------------------------------------------------------
í”„ë¡œì íŠ¸ ë£¨íŠ¸ êµ¬ì¡°:

project  
â”œâ”€ **common/**  
â”‚   â”œâ”€ `io_utils.py` : ë°ì´í„° ë¡œë“œ, Z-score í‘œì¤€í™” í•¨ìˆ˜  
â”‚   â”œâ”€ `metrics.py` : ë¡œê·¸ìš°ë„(LL), AIC/BIC, Purity, ARI, NMI ê³„ì‚°  
â”‚   â”œâ”€ `utils.py` : ìˆ˜í•™ì  ìœ í‹¸ë¦¬í‹° (logsumexp, mvn_logpdf ë“±)  
â”‚   â””â”€ `viz.py` : ì‚°ì ë„+ê°€ìš°ì‹œì•ˆ íƒ€ì›, ìˆ˜ë ´ ê³¡ì„  ì‹œê°í™” í•¨ìˆ˜  
â”‚  
â”œâ”€ **data/**  
â”‚   â”œâ”€ `G2.txt` : ê¸°ë³¸ 2D ë°ì´í„°ì…‹ (2ê°œì˜ ê°€ìš°ì‹œì•ˆ ëª¨ë“œ)  
â”‚   â”œâ”€ `g2-*.txt` : ì¶”ê°€ ìƒ˜í”Œ ë°ì´í„° (ë‹¤ì–‘í•œ N, ë¶„ì‚°ë¹„ìœ¨)  
â”‚   â””â”€ `g2-txt.zip` : ë°ì´í„° ë¬¶ìŒ ì••ì¶•ë³¸  
â”‚  
â”œâ”€ **em/**  
â”‚   â””â”€ `gmm_em.py` : EM ì•Œê³ ë¦¬ì¦˜ ì „ì²´ êµ¬í˜„ ìŠ¤í¬ë¦½íŠ¸  
â”‚        - ë¡œê·¸ìš°ë„ ê¸°ë°˜ ìˆ˜ë ´ íŒë‹¨  
â”‚        - AIC/BIC ê³„ì‚° í¬í•¨  
â”‚        - Purity/ARI/NMI ì¸¡ì •  
â”‚        - ê²°ê³¼: `runs/em_K*.png`, `runs/em_ll_K*.png`, `.npz` ì €ì¥  
â”‚  
â”œâ”€ **gibbs/**  
â”‚   â””â”€ `gmm_gibbs.py` : ë¹„ê³µë¶„ì‚°(Gibbs Sampler) ê¸°ë°˜ ë² ì´ì§€ì•ˆ GMM  
â”‚        - Dirichletâ€“Normalâ€“Inverseâ€“Wishart ì‚¬ì „ë¶„í¬ ì‚¬ìš©  
â”‚        - Burn-in, Thin ì„¤ì • ê°€ëŠ¥  
â”‚        - ê²°ê³¼: `runs/gibbs_K*.png`, `.npz`  
â”‚  
â”œâ”€ **vi/**  
â”‚   â””â”€ `gmm_vi.py` : Variational Inference ê¸°ë°˜ ê·¼ì‚¬ ì¶”ë¡   
â”‚        - ELBO ìˆ˜ë ´ê³¡ì„  ê¸°ë¡  
â”‚        - ê²°ê³¼: `runs/vi_K*.png`, `runs/vi_elbo_K*.png`, `.npz`  
â”‚  
â”œâ”€ **runs/**  
â”‚   â”œâ”€ `*_K*.png` : ê° ë°©ë²•ë³„ í´ëŸ¬ìŠ¤í„° ì‹œê°í™” ê²°ê³¼  
â”‚   â”œâ”€ `*_ll_K*.png`, `vi_elbo_K*.png` : ìˆ˜ë ´ ê³¡ì„  (LL ë˜ëŠ” ELBO)  
â”‚   â””â”€ `*.npz` : í•™ìŠµëœ íŒŒë¼ë¯¸í„° (Ï€, Î¼, Î£ ë“±) ì €ì¥  
â”‚  
â”œâ”€ **scripts/**  
â”‚   â”œâ”€ `quick_look.py` : ë°ì´í„° êµ¬ì¡° ë¹ ë¥¸ í™•ì¸ìš©  
â”‚   â””â”€ `sweep_k.py` : ì—¬ëŸ¬ K ê°’ ë°˜ë³µ ì‹¤í—˜ ìë™í™” ìŠ¤í¬ë¦½íŠ¸  
â”‚  
â””â”€ **env.yml** : Conda í™˜ê²½ ì„¤ì • íŒŒì¼ (NumPy, Matplotlib ë“± í¬í•¨)


------------------------------------------------------------------
ğŸš€ ì‹¤í–‰ ë° ë¶„ì„ ê°€ì´ë“œ
------------------------------------------------------------------
1ï¸âƒ£ **í™˜ê²½ ì„¤ì •**
```bash
conda env create -f env.yml
conda activate gmm-g2
```

2ï¸âƒ£ **EM ì‹¤í–‰ ì˜ˆì‹œ**
```bash
python em/gmm_em.py --data data/G2.txt --K 2   --max_iter 200 --tol 1e-6 --seed 42   --plot_out runs/em_K2.png --curve_out runs/em_ll_K2.png   --save_params runs/em_K2.npz --standardize 0
```

3ï¸âƒ£ **Gibbs ì‹¤í–‰ ì˜ˆì‹œ**
```bash
python gibbs/gmm_gibbs.py --data data/G2.txt --K 2   --burnin 500 --iters 2000 --thin 5 --seed 42 --standardize 0   --plot_out runs/gibbs_K2.png --save_params runs/gibbs_K2.npz
```

4ï¸âƒ£ **VI ì‹¤í–‰ ì˜ˆì‹œ**
```bash
python vi/gmm_vi.py --data data/G2.txt --K 2   --max_iter 500 --tol 1e-6 --seed 42 --standardize 0   --plot_out runs/vi_K2.png --curve_out runs/vi_elbo_K2.png   --save_params runs/vi_K2.npz
```


------------------------------------------------------------------
ğŸ“Š ê²°ê³¼ í•´ì„ í¬ì¸íŠ¸
------------------------------------------------------------------
ğŸ“ˆ **EM (Expectationâ€“Maximization)**  
- ì ì¶”ì • ê¸°ë°˜ (MLE)  
- ë¡œê·¸ìš°ë„(LL)ê°€ ë‹¨ì¡° ì¦ê°€í•˜ë©° ìˆ˜ë ´  
- BIC ìµœì†Œê°’ìœ¼ë¡œ ìµœì  K ê²°ì •  
- ê²°ê³¼ íŒŒì¼: `em_K*.png`, `em_ll_K*.png`

ğŸ”¥ **Gibbs Sampling**  
- ì‚¬í›„ë¶„í¬ ìƒ˜í”Œë§ ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ë°˜ì˜  
- Burn-in ì´í›„ ìˆ˜ì§‘í•œ ìƒ˜í”Œ í‰ê· ìœ¼ë¡œ ì¶”ì •  
- ê²°ê³¼ íŒŒì¼: `gibbs_K*.png`  
- LL_meanì€ EMì˜ LLê³¼ ì ˆëŒ€ ë¹„êµ ë¶ˆê°€ (ë‹¤ë¥¸ ì²™ë„)

ğŸ§  **Variational Inference (VI)**  
- ê·¼ì‚¬ ì¶”ë¡  ê¸°ë°˜ (ELBO ìµœëŒ€í™”)  
- ìˆ˜ë ´ ì†ë„ ë¹ ë¥´ê³  ì•ˆì •ì   
- ê²°ê³¼ íŒŒì¼: `vi_K*.png`, `vi_elbo_K*.png`


------------------------------------------------------------------
ğŸ“‘ ê²°ê³¼ ìš”ì•½ (K=2, seed=42)
------------------------------------------------------------------
- EM:    LL = -22812.15,  Purity = 0.9170,  ARI = 0.6954,  NMI = 0.5873
- Gibbs: LL_mean = -28610.33, ë™ì¼ Purity/ARI/NMI
- VI:    ELBO = 41068.09, ë™ì¼ Purity/ARI/NMI
â†’ ì„¸ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ êµ°ì§‘ êµ¬ì¡° ë„ì¶œ, K=2ê°€ ìµœì .

------------------------------------------------------------------
ğŸ§© ì°¸ê³  ì‚¬í•­
------------------------------------------------------------------
- ëª¨ë“  êµ¬í˜„ì€ NumPyë§Œ ì‚¬ìš© (SciPy, scikit-learn, OpenCV ì—†ìŒ)
- ì‹¤í–‰ ì‹œ ìƒì„±ëœ `.npz` íŒŒì¼ì—ëŠ” í•™ìŠµëœ Ï€, Î¼, Î£ ì €ì¥ë¨
- plotsëŠ” ìë™ ì €ì¥ (runs/)



